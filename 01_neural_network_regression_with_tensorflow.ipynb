{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression_with_tensorflow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMqPsXpstxOS7VFTRsdk61d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikitaion/TensorFlowLearning/blob/main/01_neural_network_regression_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cF23bd-TBw3"
      },
      "source": [
        "# Introduction to Regression with Neural Networks in TensorFlow\n",
        "\n",
        "There are many definitions for a regression problem, but in our case we're going to simplify it: predicting a numerical variable based on some other combination of variables, even shorter... predicting a number!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfysJ5Gma9mo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQjYjahTc0zp"
      },
      "source": [
        "## Creating some data to view and fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "mqYoe8gcbCRn",
        "outputId": "3181ee17-678e-4607-82eb-d4e0f154c05e"
      },
      "source": [
        "# Create feautures\n",
        "# X = np.array([-11.0, -3.0, -1.0, 2.0, 3.0, 6.0, 12.0, 14.0, 18.0, 5.0, 123.0, 909.0, 523.0, 241.0, 233.0, 45.0, 64.0, 75.0, 453.0, 345.0, 654.0, 876.0])\n",
        "X = np.array([-11.0, -3.0, -1.0, 2.0, 3.0, 6.0, 12.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "# y = np.array([-1.0, 7.0, 9.0, 12.0, 13.0, 16.0, 22.0, 24.0, 28.0, 15.0, 133.0, 919.0, 533.0, 251.0, 243.0, 55.0, 74.0, 85.0, 463.0, 355.0, 664.0, 886.0])\n",
        "y = np.array([-1.0, 7.0, 9.0, 12.0, 13.0, 16.0, 22.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y);"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v40xdwDXghIe"
      },
      "source": [
        "## Input and output shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbz-315whsDo",
        "outputId": "38f28dc3-23e4-4dc2-cbe1-0f044dd6aac4"
      },
      "source": [
        "# Create and demo tensor for our housing price prediction problem\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJJU8ES7iqKy",
        "outputId": "8eb2fa85-02a7-41dd-d7ea-76740bb658b9"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGKmn1Uri1YG",
        "outputId": "078406f6-c619-4cd8-ea4f-4ab744556003"
      },
      "source": [
        "X[0].ndim"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kGbzS8mjf_R",
        "outputId": "aa71f794-e363-4bb3-95bf-69bc8066a504"
      },
      "source": [
        "# Turn our NumPy arrays into tensors with dtype float32\n",
        "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
        "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
        "X, y"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-11.,  -3.,  -1.,   2.,   3.,   6.,  12.,  14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([-1.,  7.,  9., 12., 13., 16., 22., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YinDLH0glf4l",
        "outputId": "60f2130c-0fb7-4f5c-bad5-264e48b6e54a"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0BEGqjwlqno"
      },
      "source": [
        "## Steps in modeling with TensorFlow\n",
        "\n",
        "1. **Creating a model** - define the input/output layers, as well as the hidden layers of a deep learning model\n",
        "2. **Compile a model** - define the loss function (the function which tells our model how wrong it is) and the optimiser (tells our model how improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model)\n",
        "3. **Fitting a model** - letting the model try to find patterns betveen X and y (features and labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClxNuRCfl6-e",
        "outputId": "1cce2c2f-e1dd-454d-c14c-3823774072b2"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(seed=42)\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1) # 1 - because we want input 1 number and predict 1 number\n",
        "])\n",
        "\n",
        "# 2. Compile the model  \n",
        "model.compile(loss = tf.keras.losses.mae, # mae is short mean absolute error\n",
        "              optimizer = tf.keras.optimizers.SGD(), # SGD is short for stochastic gradient descent (is an optimizer tells our neural network how it should improve)\n",
        "              metrics=[\"mae\"])\n",
        "# loss - how wrong your model's predictions are compared to the truth labels (you want to minimise this)\n",
        "# optimize - how your model should update its internal patterns to better predictions\n",
        "# metrics - human interpretable values for how well your model is doing\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(X, y, epochs = 5) # model will have epochs = 5 opportunities of going through X and y\n",
        "# epochs - how many times the model will go through all of the training examples"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 11.1823 - mae: 11.1823\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.0967 - mae: 11.0967\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.0111 - mae: 11.0111\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.9255 - mae: 10.9255\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.8398 - mae: 10.8398\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4857fa69d0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3yvA3XYuVp8",
        "outputId": "feb95e02-cf63-4421-b6e3-3720998747c8"
      },
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-11.,  -3.,  -1.,   2.,   3.,   6.,  12.,  14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([-1.,  7.,  9., 12., 13., 16., 22., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnzVhwPcxckv",
        "outputId": "a2cad13d-e6cb-4c32-d073-6cba214145b7"
      },
      "source": [
        "# Try and make a prediction using model\n",
        "y_pred = model.predict([32.0])\n",
        "y_pred\n",
        "\n",
        "# Bad results"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22.691912]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk73KbBByTsp"
      },
      "source": [
        "## Improving our model\n",
        "\n",
        "We can improve our model, by altering the steps we took to create a model\n",
        "\n",
        "1. **Creating a model** - here we might add more layers, increase the number of hidden units (also called neurons) within each of the hidden layers, change the activation function of each layer.\n",
        "2. **Compiling a model** - here we might change the optimization function for perhaps the **learning rate** of the optimizatiion function\n",
        "3. **Fitting a model**  - here we might fit a model for more **epochs** (leave it traning for longer) or on more data (give the model more examples to learn from)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD8A8491EAvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86adb846-64b0-485b-adb0-a97f64d3024d"
      },
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "# 1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "# 2. Compile the model \n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model (this time we will train for longer)\n",
        "model.fit(X, y, epochs = 100)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 10.9601 - mae: 10.9601\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.8745 - mae: 10.8745\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.7888 - mae: 10.7888\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.7032 - mae: 10.7032\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.6176 - mae: 10.6176\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.5320 - mae: 10.5320\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.4463 - mae: 10.4463\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.3607 - mae: 10.3607\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.2751 - mae: 10.2751\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.1895 - mae: 10.1895\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.1038 - mae: 10.1038\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.0182 - mae: 10.0182\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.9326 - mae: 9.9326\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.8470 - mae: 9.8470\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.7613 - mae: 9.7613\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.6757 - mae: 9.6757\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.5901 - mae: 9.5901\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.5045 - mae: 9.5045\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.4188 - mae: 9.4188\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.3332 - mae: 9.3332\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.2476 - mae: 9.2476\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.1620 - mae: 9.1620\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.0763 - mae: 9.0763\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.9907 - mae: 8.9907\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.9051 - mae: 8.9051\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.8195 - mae: 8.8195\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.7338 - mae: 8.7338\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.6482 - mae: 8.6482\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5626 - mae: 8.5626\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.4770 - mae: 8.4770\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.3913 - mae: 8.3913\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.3057 - mae: 8.3057\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.2201 - mae: 8.2201\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1345 - mae: 8.1345\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.0488 - mae: 8.0488\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.9632 - mae: 7.9632\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.8776 - mae: 7.8776\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7920 - mae: 7.7920\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.7369 - mae: 7.7369\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.7257 - mae: 7.7257\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.7326 - mae: 7.7326\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.7275 - mae: 7.7275\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.7163 - mae: 7.7163\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.7050 - mae: 7.7050\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.6938 - mae: 7.6938\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.6995 - mae: 7.6995\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6957 - mae: 7.6957\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.6844 - mae: 7.6844\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6732 - mae: 7.6732\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.6619 - mae: 7.6619\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6663 - mae: 7.6663\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6638 - mae: 7.6638\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6525 - mae: 7.6525\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6413 - mae: 7.6413\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.6300 - mae: 7.6300\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.6332 - mae: 7.6332\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.6319 - mae: 7.6319\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.6207 - mae: 7.6207\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6094 - mae: 7.6094\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.5982 - mae: 7.5982\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6001 - mae: 7.6001\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6000 - mae: 7.6000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5888 - mae: 7.5888\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.5775 - mae: 7.5775\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5663 - mae: 7.5663\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5670 - mae: 7.5670\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.5682 - mae: 7.5682\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5569 - mae: 7.5569\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5457 - mae: 7.5457\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.5344 - mae: 7.5344\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5338 - mae: 7.5338\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.5363 - mae: 7.5363\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.5250 - mae: 7.5250\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.5138 - mae: 7.5138\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.5025 - mae: 7.5025\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5007 - mae: 7.5007\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.5044 - mae: 7.5044\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.4932 - mae: 7.4932\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4819 - mae: 7.4819\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.4707 - mae: 7.4707\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.4676 - mae: 7.4676\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.4725 - mae: 7.4725\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.4613 - mae: 7.4613\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.4500 - mae: 7.4500\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4388 - mae: 7.4388\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.4345 - mae: 7.4345\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.4407 - mae: 7.4407\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.4294 - mae: 7.4294\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.4182 - mae: 7.4182\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.4069 - mae: 7.4069\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4013 - mae: 7.4013\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.4088 - mae: 7.4088\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3975 - mae: 7.3975\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.3863 - mae: 7.3863\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.3750 - mae: 7.3750\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.3682 - mae: 7.3682\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.3769 - mae: 7.3769\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.3657 - mae: 7.3657\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.3544 - mae: 7.3544\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.3432 - mae: 7.3432\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f485a8d6e50>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD6DL7d-e7ub",
        "outputId": "a2a44f98-474d-4883-88ae-9c2f878d047a"
      },
      "source": [
        "# Remind ourselves of the data\n",
        "X, y"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-11.,  -3.,  -1.,   2.,   3.,   6.,  12.,  14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([-1.,  7.,  9., 12., 13., 16., 22., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjaoemm3f1xE",
        "outputId": "eb2de16e-d562-4acb-ff41-4e3f6d0daa19"
      },
      "source": [
        "# Let's see if our model's prediction has improved\n",
        "model.predict([12.0]), model.predict([10.0]), model.predict([-32.0]), model.predict([132.0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f485a834200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[20.68547]], dtype=float32),\n",
              " array([[17.383726]], dtype=float32),\n",
              " array([[-51.952923]], dtype=float32),\n",
              " array([[218.79018]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrjJnr8hgJec",
        "outputId": "ff9ee008-c2a0-4237-a7bf-89cdf09e573f"
      },
      "source": [
        "# Let's try to do better\n",
        "\n",
        "# 1. Create the model (this time with extra layers)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "# 2. Compile the model (this time with another optimizer with changed learning_rate)\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.1),\n",
        "              metrics=[\"mae\"])\n",
        "# Note: the learning rate is a most important hyper parameter of many different known networks.\n",
        "\n",
        "# 3. Fit the model \n",
        "model.fit(X, y, epochs = 100)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 11.5667 - mae: 11.5667\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.5267 - mae: 8.5267\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7317 - mae: 5.7317\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.5478 - mae: 6.5478\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7208 - mae: 5.7208\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5518 - mae: 4.5518\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.0236 - mae: 4.0236\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.6773 - mae: 3.6773\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5447 - mae: 3.5447\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9753 - mae: 2.9753\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.5324 - mae: 2.5324\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7979 - mae: 1.7979\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9316 - mae: 1.9316\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1439 - mae: 2.1439\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7077 - mae: 1.7077\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9940 - mae: 0.9940\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9139 - mae: 0.9139\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8347 - mae: 1.8347\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6939 - mae: 1.6939\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2730 - mae: 1.2730\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9393 - mae: 0.9393\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8117 - mae: 0.8117\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8320 - mae: 0.8320\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6996 - mae: 1.6996\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3775 - mae: 1.3775\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2453 - mae: 1.2453\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1804 - mae: 1.1804\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6418 - mae: 0.6418\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5807 - mae: 0.5807\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9430 - mae: 0.9430\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6782 - mae: 0.6782\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8067 - mae: 0.8067\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8559 - mae: 0.8559\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5487 - mae: 0.5487\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8522 - mae: 0.8522\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3456 - mae: 0.3456\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9604 - mae: 0.9604\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9615 - mae: 0.9615\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2362 - mae: 0.2362\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2033 - mae: 1.2033\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1574 - mae: 1.1574\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3240 - mae: 0.3240\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6588 - mae: 1.6588\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2263 - mae: 2.2263\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6334 - mae: 1.6334\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2155 - mae: 0.2155\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8722 - mae: 1.8722\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8519 - mae: 2.8519\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0627 - mae: 3.0627\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5702 - mae: 2.5702\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4554 - mae: 1.4554\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4741 - mae: 0.4741\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2670 - mae: 1.2670\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1206 - mae: 1.1206\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1430 - mae: 0.1430\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5434 - mae: 0.5434\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2387 - mae: 0.2387\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9876 - mae: 0.9876\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1847 - mae: 1.1847\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5557 - mae: 0.5557\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9253 - mae: 0.9253\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3596 - mae: 1.3596\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9847 - mae: 0.9847\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2187 - mae: 0.2187\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4872 - mae: 0.4872\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5432 - mae: 0.5432\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3435 - mae: 0.3435\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6837 - mae: 0.6837\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6744 - mae: 0.6744\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4026 - mae: 0.4026\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2873 - mae: 0.2873\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6183 - mae: 0.6183\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6150 - mae: 0.6150\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1620 - mae: 0.1620\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1054 - mae: 0.1054\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7838 - mae: 0.7838\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6563 - mae: 0.6563\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3316 - mae: 0.3316\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4780 - mae: 0.4780\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2310 - mae: 0.2310\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1537 - mae: 0.1537\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3737 - mae: 0.3737\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3021 - mae: 0.3021\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1351 - mae: 0.1351\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4731 - mae: 0.4731\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2459 - mae: 0.2459\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5896 - mae: 0.5896\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4848 - mae: 0.4848\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5489 - mae: 0.5489\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5495 - mae: 0.5495\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4901 - mae: 0.4901\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5057 - mae: 0.5057\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1647 - mae: 0.1647\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1971 - mae: 0.1971\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5087 - mae: 0.5087\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4026 - mae: 0.4026\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4474 - mae: 0.4474\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1809 - mae: 0.1809\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1365 - mae: 0.1365\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5126 - mae: 0.5126\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f485b83f990>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_N_UD7vgKbw",
        "outputId": "b0789d0b-2c5c-4edc-8e01-631884209d03"
      },
      "source": [
        "model.predict([12.0]), model.predict([10.0]), model.predict([-11.0]), model.predict([45.0])\n",
        "#Thats better"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4857746830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[20.848778]], dtype=float32),\n",
              " array([[19.065048]], dtype=float32),\n",
              " array([[-0.74188113]], dtype=float32),\n",
              " array([[50.852535]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwVjigcPiSnZ"
      },
      "source": [
        "## Evaluating a model (tommorow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_kN3WzpuZwp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}