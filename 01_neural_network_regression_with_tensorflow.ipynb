{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression_with_tensorflow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPZWWUynq4lpJo8ySTF5WPM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikitaion/TensorFlowLearning/blob/main/01_neural_network_regression_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cF23bd-TBw3"
      },
      "source": [
        "# Introduction to Regression with Neural Networks in TensorFlow\n",
        "\n",
        "There are many definitions for a regression problem, but in our case we're going to simplify it: predicting a numerical variable based on some other combination of variables, even shorter... predicting a number!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfysJ5Gma9mo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQjYjahTc0zp"
      },
      "source": [
        "## Creating some data to view and fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "mqYoe8gcbCRn",
        "outputId": "e51a04a3-f69f-4be0-b0da-db4a842c77da"
      },
      "source": [
        "# Create feautures\n",
        "# X = np.array([-11.0, -3.0, -1.0, 2.0, 3.0, 6.0, 12.0, 14.0, 18.0, 5.0, 123.0, 909.0, 523.0, 241.0, 233.0, 45.0, 64.0, 75.0, 453.0, 345.0, 654.0, 876.0])\n",
        "X = np.array([-11.0, -3.0, -1.0, 2.0, 3.0, 6.0, 12.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "# y = np.array([-1.0, 7.0, 9.0, 12.0, 13.0, 16.0, 22.0, 24.0, 28.0, 15.0, 133.0, 919.0, 533.0, 251.0, 243.0, 55.0, 74.0, 85.0, 463.0, 355.0, 664.0, 886.0])\n",
        "y = np.array([-1.0, 7.0, 9.0, 12.0, 13.0, 16.0, 22.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y);"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v40xdwDXghIe"
      },
      "source": [
        "## Input and output shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbz-315whsDo",
        "outputId": "83d6805b-fccc-470b-ae57-55aea8197f69"
      },
      "source": [
        "# Create and demo tensor for our housing price prediction problem\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJJU8ES7iqKy",
        "outputId": "b2b19c45-9608-4a2a-9f28-bff1f42fe99e"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGKmn1Uri1YG",
        "outputId": "c53ffa6f-fc97-47e2-dc64-128b8b3b338f"
      },
      "source": [
        "X[0].ndim"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kGbzS8mjf_R",
        "outputId": "50d27c29-b397-4c3b-e319-fb465ea48be3"
      },
      "source": [
        "# Turn our NumPy arrays into tensors with dtype float32\n",
        "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
        "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
        "X, y"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-11.,  -3.,  -1.,   2.,   3.,   6.,  12.,  14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([-1.,  7.,  9., 12., 13., 16., 22., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YinDLH0glf4l",
        "outputId": "a7213d40-99c3-4cbf-b6b9-cc21a02a1bd1"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0BEGqjwlqno"
      },
      "source": [
        "## Steps in modeling with TensorFlow\n",
        "\n",
        "1. **Creating a model** - define the input/output layers, as well as the hidden layers of a deep learning model\n",
        "2. **Compile a model** - define the loss function (the function which tells our model how wrong it is) and the optimiser (tells our model how improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model)\n",
        "3. **Fitting a model** - letting the model try to find patterns betveen X and y (features and labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "ClxNuRCfl6-e",
        "outputId": "e210ee9e-8905-4fe4-fc67-36bddf1f5988"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(seed=42)\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1) # 1 - because we want input 1 number and predict 1 number\n",
        "])\n",
        "\n",
        "# 2. Compile the model  \n",
        "model.compile(loss = tf.keras.losses.mae, # mae is short mean absolute error\n",
        "              optimizer = tf.keras.optimizers.SGD(), # SGD is short for stochastic gradient descent (is an optimizer tells our neural network how it should improve)\n",
        "              metrics=[\"mae\"])\n",
        "# loss - how wrong your model's predictions are compared to the truth labels (you want to minimise this)\n",
        "# optimize - how your model should update its internal patterns to better predictions\n",
        "# metrics - human interpretable values for how well your model is doing\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(X, y, epochs = 5) # model will have epochs = 5 opportunities of going through X and y\n",
        "# epochs - how many times the model will go through all of the training examples"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-b77ad600eaec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 3. Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# model will have epochs = 5 opportunities of going through X and y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# epochs - how many times the model will go through all of the training examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 227, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_4\" (type Sequential).\n    \n    Input 0 of layer \"dense_4\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received:\n      â€¢ inputs=tf.Tensor(shape=(None,), dtype=float32)\n      â€¢ training=True\n      â€¢ mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3yvA3XYuVp8",
        "outputId": "aaf2181d-c8fa-4c2b-c928-9b079ce1b615"
      },
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-11.,  -3.,  -1.,   2.,   3.,   6.,  12.,  14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([-1.,  7.,  9., 12., 13., 16., 22., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "pnzVhwPcxckv",
        "outputId": "d376c788-dfc8-4b73-fff8-aafdbc1b5308"
      },
      "source": [
        "# Try and make a prediction using model\n",
        "y_pred = model.predict([32.0])\n",
        "y_pred\n",
        "\n",
        "# Bad results"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-efbf34b670d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Try and make a prediction using model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Bad results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 227, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_3\" (type Sequential).\n    \n    Input 0 of layer \"dense_3\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received:\n      â€¢ inputs=tf.Tensor(shape=(None,), dtype=float32)\n      â€¢ training=False\n      â€¢ mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk73KbBByTsp"
      },
      "source": [
        "## Improving our model\n",
        "\n",
        "We can improve our model, by altering the steps we took to create a model\n",
        "\n",
        "1. **Creating a model** - here we might add more layers, increase the number of hidden units (also called neurons) within each of the hidden layers, change the activation function of each layer.\n",
        "2. **Compiling a model** - here we might change the optimization function for perhaps the **learning rate** of the optimizatiion function\n",
        "3. **Fitting a model**  - here we might fit a model for more **epochs** (leave it traning for longer) or on more data (give the model more examples to learn from)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD8A8491EAvZ"
      },
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "# 1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "# 2. Compile the model \n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model (this time we will train for longer)\n",
        "model.fit(X, y, epochs = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD6DL7d-e7ub"
      },
      "source": [
        "# Remind ourselves of the data\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjaoemm3f1xE"
      },
      "source": [
        "# Let's see if our model's prediction has improved\n",
        "model.predict([12.0]), model.predict([10.0]), model.predict([-32.0]), model.predict([132.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrjJnr8hgJec"
      },
      "source": [
        "# Let's try to do better\n",
        "\n",
        "# 1. Create the model (this time with extra layers)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "# 2. Compile the model (this time with another optimizer with changed learning_rate)\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.1),\n",
        "              metrics=[\"mae\"])\n",
        "# Note: the learning rate is a most important hyper parameter of many different known networks.\n",
        "\n",
        "# 3. Fit the model \n",
        "model.fit(X, y, epochs = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_N_UD7vgKbw"
      },
      "source": [
        "model.predict([12.0]), model.predict([10.0]), model.predict([-11.0]), model.predict([45.0])\n",
        "#Thats better"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwVjigcPiSnZ"
      },
      "source": [
        "## Evaluating a model\n",
        "\n",
        "In practice, a typical workflow you'll go through when building neural networks is:\n",
        "\n",
        "```\n",
        "Build a model -> fit it -> evaluate it -> tweak a model -> fit it -> \n",
        "evaluate it -> tweak a model -> fit it -> evaluate it ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_kN3WzpuZwp"
      },
      "source": [
        "When it comes to evaluation - there are 3 words you should memorize:\n",
        "\n",
        ">\"Visualise, visualise, visualise\"\n",
        "\n",
        "It's a good idea to visualize:\n",
        "* The data - what data are we working with? What does it look like?\n",
        "* The model itself. What does our model look like?\n",
        "* The training of a model - how does a model perform while it learns?\n",
        "* The predictions of a model - how do the predictions of a modelline up against the ground truth (the original labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raCHB-ZYR0-w"
      },
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL5KJYIFUcIi"
      },
      "source": [
        "# Make labels for the dataset\n",
        "y = X + 10\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnD9Tc42UnEh"
      },
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-mwZj0bU503"
      },
      "source": [
        "### The 3 sets\n",
        "\n",
        "* **Training set** - the model learns from this data. Typically 70-80 percent of the total avaliable data\n",
        "* **Validation set** - the model gets tuned on this data. Typically 10-15 percent of the total avaliable data\n",
        "* **Test set** - the model gets evaluated on this data to test what it has learned. Typically 10-15 percent of the total data available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgSowwnxKEcG"
      },
      "source": [
        "# Check the length of how many samples we have\n",
        "len(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdJXpHLiKE4j"
      },
      "source": [
        "# Split the data into train and test set\n",
        "X_train = X[:40] # First 40 training samples (80% data)\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:] # Last 10 samples (20% data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBOlfAQGK9fh"
      },
      "source": [
        "### Visualizing the data \n",
        "Now we've got our data in training and test sets. Let's visualise it again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1WZ4BA9LKI5"
      },
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "# Plot training data in blue\n",
        "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
        "# Plot test data in green\n",
        "plt.scatter(X_test, y_test, c=\"g\", label=\"Testing data\")\n",
        "# Show a legend\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5IDBXpu0upR"
      },
      "source": [
        "# Let's have a look at let's have a look at how to build a neural network for our data.\n",
        "\n",
        "# 1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "# 2. Compile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "# 3. Fit the model\n",
        "# model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng2pAZUt2bYl"
      },
      "source": [
        "### Visualizing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUkvahPb2nyt"
      },
      "source": [
        "# let's create a model which builds automatically by defining the input shape argument in the first layer\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model. Same as above\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape=[1], name=\"Input_layer\"), # input_shape=1 because we passing 1 number to predict 1 number\n",
        "    tf.keras.layers.Dense(1, name=\"Output_layer\")\n",
        "], name=\"model_1\")\n",
        "\n",
        "# 2. Compile a model. Same as above\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rK4_y4xMoA1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-WwahHf2rmc"
      },
      "source": [
        "* Total params - total number of parameters in the model.\n",
        "* Trainable parameters - these are the parameters (patterns) the model can update as it trains.\n",
        "* Non trainable parameters - these parameters aren't updated during training (this is typical when you bring in already learned patterns or parameters from other models during **transfer learning**).\n",
        "\n",
        "https://deeplizard.com/learn/video/8d-9SnGt5E0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqbErag85GlW"
      },
      "source": [
        "# Let's fit a model to the training data\n",
        "model.fit(X_train, y_train, epochs=100, verbose=0) # verbose=0 for do it without many outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JepH6Ta7koH"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdXE1IAJL0t2"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model=model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XarMsVv8NhCj"
      },
      "source": [
        "### Visualizing our models predictions\n",
        "\n",
        "To visualize predictions, it's a good idea to plot them against the ground truth labels.\n",
        "\n",
        "Often you'll see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus your model's predictions).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzS7JSYWPtGB"
      },
      "source": [
        "# Make some predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZepAlHacIyX"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOnvhdM6c1KS"
      },
      "source": [
        "ðŸ”‘**Note:** If you feel like You're going to reuse some kind of functionality in the future, it's a good idea to turn it into a function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrV-4rpKdKzf"
      },
      "source": [
        "# Let's create a plotting func\n",
        "def plot_predictions(train_data=X_train, train_labels=y_train, test_data=X_test, test_labels=y_test, predictions=y_pred):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compare predictions to ground truth labels\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
        "  # Plot testing data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
        "  # Plot model's predictions in a res\n",
        "  plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
        "  # Show the legent\n",
        "  plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sfM_hzlcNHz"
      },
      "source": [
        "# plt.figure(figsize=(10, 7))\n",
        "# # Plot training data in blue\n",
        "# plt.scatter(X_test, y_pred, c=\"b\", label=\"Predicted data\")\n",
        "# # Plot test data in green\n",
        "# plt.scatter(X_test, y_test, c=\"g\", label=\"Testing data\")\n",
        "# # Show a legend\n",
        "# plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it9rCKP0cXlI"
      },
      "source": [
        "plot_predictions(train_data=X_train, train_labels=y_train, test_data=X_test, test_labels=y_test, predictions=y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CUo5GowmQXS"
      },
      "source": [
        "# Let's try to do better\n",
        "tf.random.set_seed(42)\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape=[1], name=\"Input_layer\"),\n",
        "    # tf.keras.layers.Dense(100, input_shape=[1], name=\"Input_layer\"), # With 100 units worse\n",
        "    # tf.keras.layers.Dense(10, input_shape=[1], name=\"Second_layer\"), # With second layer - pretty worst\n",
        "    tf.keras.layers.Dense(1, name=\"Output_layer\")\n",
        "], name=\"model_2\")\n",
        "\n",
        "model_2.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.015), # With Adam lr=0.015 - better\n",
        "              metrics=[\"mae\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3fnzqLfmf7c"
      },
      "source": [
        "model_2.fit(X_train, y_train, epochs=100, verbose=0) # verbose=0 for do it without many outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkN3Q9Y6mpaJ"
      },
      "source": [
        "plot_model(model_2, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvseG5Cjm7DB"
      },
      "source": [
        "y_pred_2 = model_2.predict(X_test)\n",
        "y_pred_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8CwODWEnEmv"
      },
      "source": [
        "plot_predictions(predictions=y_pred_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed1JS2P5eWJt"
      },
      "source": [
        "### Evaluating our model's predictions with regression evaluation metrics\n",
        "\n",
        "Depending on the problem you're working on, there will be different evaluation metrics to evaluate your model's performance.\n",
        "\n",
        "Since we're working on a regression problem, two of the main metrics:\n",
        "* MAE - mean absolute error, \"on average, how wrong is each of my model's predictions?\". As a great starter metric for any regression problem \n",
        "( tf.keras.losses.MAE() & tf.metrics.mean_absolute_error() )\n",
        "* MSE - mean squared error, \"square the average errors\". When larger errors are more significant than saller errors.\n",
        "( tf.keras.losses.MSE() & tf.metrics.mean_squared_error() )\n",
        "* Huber - Combination of MSE and MAE. Less sensitive to outliers than MSE\n",
        "( tf.keras.losses.Huber() )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfXhp3MFnMlq"
      },
      "source": [
        "# Evaluate the model on the test set\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL8mP3_3uf3w"
      },
      "source": [
        "# Calculate the mean ablolute error\n",
        "tf.keras.losses.MAE(y_true = y_test, y_pred=tf.squeeze(y_pred)) # We need to squeeze because y_pred have 1 extra dimension (shape=(10, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nCCUaqmvnQ1"
      },
      "source": [
        " tf.metrics.mean_absolute_error(y_test, tf.squeeze(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYZtSLy1uRgg"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K66fb1yCudSV"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNZtCxrsueHP"
      },
      "source": [
        "tf.constant(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mow-7Wlyg2V"
      },
      "source": [
        "tf.constant(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAny3L40yjk7"
      },
      "source": [
        "tf.squeeze(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIWb5w_8zBJX"
      },
      "source": [
        "# Calculate the mean square error\n",
        "tf.keras.losses.MSE(y_true = y_test, y_pred=tf.squeeze(y_pred)) # We need to squeeze because y_pred have 1 extra dimension (shape=(10, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6RSkNyVziXx"
      },
      "source": [
        "# Make some functions to reuse MAE and MSE\n",
        "def mae(y_true, y_pred):\n",
        "  return tf.metrics.mean_absolute_error(y_true=y_true,\n",
        "                                        y_pred=y_pred)\n",
        "\n",
        "def mse(y_true, y_pred):\n",
        "  return tf.metrics.mean_squared_error(y_true=y_true,\n",
        "                                        y_pred=y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O37fAR9416er"
      },
      "source": [
        "mae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_oqnRhwOrv1"
      },
      "source": [
        "mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziJbjjXbOswW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}