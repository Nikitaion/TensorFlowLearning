{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikitaion/TensorFlowLearning/blob/main/05_transfer_learning_in_tensorflow_part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyQM4G99xSPs"
      },
      "source": [
        "# 05. Transfer Learning with TensorFlow Part 2: Fine-tuning\n",
        "\n",
        "In the previous section, we saw how we could leverage feature extraction transfer learning to get far better results on our Food Vision project than building our own models (even with less data).\n",
        "\n",
        "Now we're going to cover another type of transfer learning: fine-tuning.\n",
        "\n",
        "In **fine-tuning transfer learning** the pre-trained model weights from another model are unfrozen and tweaked during to better suit your own data.\n",
        "\n",
        "For feature extraction transfer learning, you may only train the top 1-3 layers of a pre-trained model with your own data, in fine-tuning transfer learning, you might train 1-3+ layers of a pre-trained model (where the '+' indicates that many or all of the layers could be trained)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0SlZLyEv654D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0f170b8-019a-4fee-8d48-aedea85ade09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-05 17:49:16--  https://raw.githubusercontent.com/Nikitaion/TensorFlowLearning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: â€˜helper_functions.py.2â€™\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-05 17:49:16 (91.8 MB/s) - â€˜helper_functions.py.2â€™ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Creating helper functions\n",
        "# Throughout course we come across snippets of code you want to use over and over again.\n",
        "# A good idea to put functions which we'll want to use again in a script we can download and import into notebooks\n",
        "!wget https://raw.githubusercontent.com/Nikitaion/TensorFlowLearning/main/extras/helper_functions.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mwyFKB0-7yRl"
      },
      "outputs": [],
      "source": [
        "# Import helper_functions what we're going to use in this notebook\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdMvaW0q7KzX"
      },
      "source": [
        "> ðŸ”‘ **Note:** If you're running this notebook in Google Colab, when it times out Colab will delete the `helper_functions.py` file. So to use the functions imported above, you'll have to rerun the cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l-s9JlJ8cb8"
      },
      "source": [
        "## 10 Food Classes: Working with less data\n",
        "\n",
        "We saw in the [previous notebook](https://github.com/Nikitaion/TensorFlowLearning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb) that we could get great results with only 10% of the training data using transfer learning with TensorFlow Hub.\n",
        "\n",
        "In this notebook, we're going to continue to work with smaller subsets of the data, except this time we'll have a look at how we can use the in-built pretrained models within the `tf.keras.applications` module as well as how to fine-tune them to our own custom dataset.\n",
        "\n",
        "We'll also practice using a new but similar dataloader function to what we've used before, [`image_dataset_from_directory()`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory) which is part of the [`tf.keras.preprocessing`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing) module.\n",
        "\n",
        "Finally, we'll also be practicing using the [Keras Functional API](https://keras.io/guides/functional_api/) for building deep learning models. The Functional API is a more flexible way to create models than the tf.keras.Sequential API.\n",
        "\n",
        "We'll explore each of these in more detail as we go.\n",
        "\n",
        "Let's start by downloading some data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThHcibdM_TdU",
        "outputId": "75cd00c4-645d-41fe-bb60-94c3f6837720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-05 15:52:21--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.195.128, 173.194.196.128, 173.194.197.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: â€˜10_food_classes_10_percent.zipâ€™\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   244MB/s    in 0.7s    \n",
            "\n",
            "2022-01-05 15:52:22 (244 MB/s) - â€˜10_food_classes_10_percent.zipâ€™ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get 10% of training data of 10 classes of Food101\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# Use unzip_data from our helper functions\n",
        "unzip_data(\"10_food_classes_10_percent.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV3CIJgO_fq5",
        "outputId": "d3b20eba-83c8-49e2-e9bf-3be7f2c9676a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n"
          ]
        }
      ],
      "source": [
        "# Check out how many images and subdirectories are in our dataset\n",
        "walk_through_dir(\"10_food_classes_10_percent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bKvhp7MQAJhS"
      },
      "outputs": [],
      "source": [
        "# Create training and test directory paths\n",
        "train_dir = \"10_food_classes_10_percent/train\"\n",
        "test_dir = \"10_food_classes_10_percent/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N7XhoxcA3Gn",
        "outputId": "ddcf9908-3b62-4218-ee60-987c8f8aca21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
        "                                                                            image_size=IMG_SIZE,\n",
        "                                                                            label_mode=\"categorical\",\n",
        "                                                                            batch_size=BATCH_SIZE)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
        "                                                                image_size=IMG_SIZE,\n",
        "                                                                label_mode=\"categorical\",\n",
        "                                                                batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIJV-3pZA97l",
        "outputId": "e8c2be2b-21d8-4a7a-e15c-377e67b4b519"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 224, 224, 3), (None, 10)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_data_10_percent\n",
        "# We are turned our data into batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27eSVdEk3jqO"
      },
      "source": [
        "In the above output:\n",
        "\n",
        "* `(None, 224, 224, 3)` refers to the tensor shape of our images where `None` is the batch size, `224` is the height (and width) and `3` is the color channels (red, green, blue).\n",
        "* `(None, 10)` refers to the tensor shape of the labels where `None` is the batch size and `10` is the number of possible labels (the 10 different food classes).\n",
        "* Both image tensors and labels are of the datatype `tf.float32`.\n",
        "\n",
        "The `batch_size` is `None` due to it only being used during model training. You can think of `None` as a placeholder waiting to be filled with the `batch_size` parameter from `image_dataset_from_directory()`.\n",
        "\n",
        "Another benefit of using the `tf.data.Dataset` API are the assosciated methods which come with it.\n",
        "\n",
        "For example, if we want to find the name of the classes we were working with, we could use the `class_names` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4pY-2U72HhA",
        "outputId": "eea11f05-48bb-49e2-b87f-324919b8eff3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Check out class names of our dataset\n",
        "train_data_10_percent.class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq8Po-sy2Ibw",
        "outputId": "ea599148-c6ac-4786-e316-b97099eb32b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[  0.          0.          0.       ]\n",
            "   [  0.          0.          0.       ]\n",
            "   [  2.5714288   2.5714288   2.5714288]\n",
            "   ...\n",
            "   [ 45.867462   45.867462   46.428703 ]\n",
            "   [ 54.617355   54.617355   56.617355 ]\n",
            "   [ 55.571465   55.571465   57.571465 ]]\n",
            "\n",
            "  [[  1.          1.          1.       ]\n",
            "   [  1.          1.          1.       ]\n",
            "   [  3.1989796   3.1989796   3.1989796]\n",
            "   ...\n",
            "   [ 49.51537    49.51537    51.11745  ]\n",
            "   [ 53.142857   53.142857   55.142857 ]\n",
            "   [ 54.2398     54.2398     56.2398   ]]\n",
            "\n",
            "  [[  1.          1.          1.       ]\n",
            "   [  1.          1.          1.       ]\n",
            "   [  2.382653    2.382653    2.382653 ]\n",
            "   ...\n",
            "   [ 51.571472   51.571472   53.571472 ]\n",
            "   [ 54.27042    53.484703   57.841846 ]\n",
            "   [ 57.357178   56.571465   60.928608 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[188.49487   190.49487   187.49487  ]\n",
            "   [188.85713   190.85713   187.85713  ]\n",
            "   [187.99998   189.99998   188.99998  ]\n",
            "   ...\n",
            "   [158.99997   159.99997   163.99997  ]\n",
            "   [160.        161.        165.       ]\n",
            "   [157.28564   158.28564   162.28564  ]]\n",
            "\n",
            "  [[185.71426   187.71426   184.71426  ]\n",
            "   [187.14284   189.14284   186.14284  ]\n",
            "   [186.68365   188.68365   187.68365  ]\n",
            "   ...\n",
            "   [157.28568   158.28568   162.28568  ]\n",
            "   [159.07141   160.07141   164.07141  ]\n",
            "   [157.28564   158.28564   162.28564  ]]\n",
            "\n",
            "  [[186.05612   188.05612   185.05612  ]\n",
            "   [187.07143   189.07143   186.07143  ]\n",
            "   [188.63776   190.63776   189.63776  ]\n",
            "   ...\n",
            "   [156.07652   157.07652   161.07652  ]\n",
            "   [156.35715   157.35715   161.35715  ]\n",
            "   [157.        158.        162.       ]]]\n",
            "\n",
            "\n",
            " [[[ 77.64286    99.64286   149.64285  ]\n",
            "   [ 77.68017    99.68017   149.68016  ]\n",
            "   [ 78.55836   100.55836   150.55835  ]\n",
            "   ...\n",
            "   [ 65.42426    92.35665   103.74541  ]\n",
            "   [ 52.429977   80.355385   92.392685 ]\n",
            "   [ 48.61767    78.164246   89.39095  ]]\n",
            "\n",
            "  [[ 80.        102.        152.       ]\n",
            "   [ 80.92857   102.92857   152.92857  ]\n",
            "   [ 80.92857   102.92857   152.92857  ]\n",
            "   ...\n",
            "   [ 57.163578   81.14123    93.54307  ]\n",
            "   [ 53.164772   79.13773    92.12431  ]\n",
            "   [ 50.37371    77.718765   90.04624  ]]\n",
            "\n",
            "  [[ 79.35268   101.35268   151.35268  ]\n",
            "   [ 80.25989   102.25989   152.25989  ]\n",
            "   [ 81.        103.        153.       ]\n",
            "   ...\n",
            "   [ 66.69519    88.69519   101.93182  ]\n",
            "   [ 67.24744    90.18942   104.18942  ]\n",
            "   [ 56.405823   82.40582    95.40582  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[104.35268   134.35268   184.35268  ]\n",
            "   [105.15623   135.15623   187.15623  ]\n",
            "   [103.28731   133.28731   185.28731  ]\n",
            "   ...\n",
            "   [139.81407   157.81407   160.61446  ]\n",
            "   [139.21426   157.21426   161.21426  ]\n",
            "   [137.78119   155.78119   159.78119  ]]\n",
            "\n",
            "  [[103.97481   133.97481   183.97481  ]\n",
            "   [103.92856   133.92856   185.92856  ]\n",
            "   [103.98309   133.9831    185.9831   ]\n",
            "   ...\n",
            "   [140.87402   155.87402   158.87402  ]\n",
            "   [140.92856   155.92856   158.92856  ]\n",
            "   [141.        156.        161.       ]]\n",
            "\n",
            "  [[103.64732   133.64732   183.64732  ]\n",
            "   [102.05804   132.05803   184.05803  ]\n",
            "   [104.03606   134.03606   186.03606  ]\n",
            "   ...\n",
            "   [137.37016   152.37016   155.37016  ]\n",
            "   [138.24835   153.24835   156.24835  ]\n",
            "   [138.93298   153.93298   156.93298  ]]]\n",
            "\n",
            "\n",
            " [[[196.61224   190.43878   171.02551  ]\n",
            "   [193.66327   190.52042   172.7143   ]\n",
            "   [187.35715   188.41837   174.14795  ]\n",
            "   ...\n",
            "   [101.64292    62.994926   45.70414  ]\n",
            "   [102.97959    63.933662   49.07144  ]\n",
            "   [105.04084    64.32655    53.61227  ]]\n",
            "\n",
            "  [[193.42857   189.29082   172.47958  ]\n",
            "   [190.4949    188.34183   173.07143  ]\n",
            "   [191.64287   192.12755   180.19897  ]\n",
            "   ...\n",
            "   [ 99.78576    65.785736   52.903145 ]\n",
            "   [ 99.862206   62.79078    54.576492 ]\n",
            "   [ 95.188774   58.117344   51.90306  ]]\n",
            "\n",
            "  [[194.80103   195.09694   179.80612  ]\n",
            "   [194.04082   195.2551    181.14285  ]\n",
            "   [192.76021   193.43367   181.5255   ]\n",
            "   ...\n",
            "   [ 91.68363    63.234684   57.326557 ]\n",
            "   [ 87.658165   58.51531    57.158165 ]\n",
            "   [ 91.36739    60.65311    62.081684 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[173.93878   171.15305   161.51025  ]\n",
            "   [173.71431   173.71431   161.71431  ]\n",
            "   [171.38263   173.8112    160.59692  ]\n",
            "   ...\n",
            "   [174.38261   184.38261   176.38261  ]\n",
            "   [172.34184   182.34184   173.22957  ]\n",
            "   [174.92351   183.35204   172.78056  ]]\n",
            "\n",
            "  [[170.78574   167.78574   158.78574  ]\n",
            "   [173.06636   173.06636   163.06636  ]\n",
            "   [168.4133    170.84187   159.19902  ]\n",
            "   ...\n",
            "   [175.        185.05614   173.88773  ]\n",
            "   [175.14288   183.14288   170.13268  ]\n",
            "   [177.54587   185.54587   171.73965  ]]\n",
            "\n",
            "  [[174.12753   171.12753   164.12753  ]\n",
            "   [175.42854   175.42854   167.42854  ]\n",
            "   [173.06636   175.28064   164.28064  ]\n",
            "   ...\n",
            "   [175.49495   184.13774   170.92348  ]\n",
            "   [173.71426   181.71426   166.71426  ]\n",
            "   [173.21411   181.80089   165.62733  ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 29.41837    22.41837    14.418368 ]\n",
            "   [ 26.520409   19.520409   13.52041  ]\n",
            "   [ 18.999998   11.999999    5.9999995]\n",
            "   ...\n",
            "   [  6.          9.         14.       ]\n",
            "   [  5.071411    8.071411   13.071411 ]\n",
            "   [  5.          8.         13.       ]]\n",
            "\n",
            "  [[ 27.836731   20.836731   14.836733 ]\n",
            "   [ 43.285713   36.285713   30.285713 ]\n",
            "   [ 55.857147   48.857147   42.857147 ]\n",
            "   ...\n",
            "   [  6.          9.         14.       ]\n",
            "   [  5.071411    8.071411   13.071411 ]\n",
            "   [  5.          8.         13.       ]]\n",
            "\n",
            "  [[ 29.943876   22.729591   17.372448 ]\n",
            "   [ 32.64286    25.42857    20.071428 ]\n",
            "   [ 38.234695   30.40306    26.89796  ]\n",
            "   ...\n",
            "   [  6.          9.         14.       ]\n",
            "   [  5.071411    8.071411   13.071411 ]\n",
            "   [  5.          8.         13.       ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[145.28564   147.07138   107.07139  ]\n",
            "   [145.78564   147.57138   107.57139  ]\n",
            "   [148.26016   150.0459    110.04589  ]\n",
            "   ...\n",
            "   [153.99997   150.16832   111.83165  ]\n",
            "   [153.21426   149.21426   112.       ]\n",
            "   [153.78574   149.78574   114.35721  ]]\n",
            "\n",
            "  [[148.0714    153.0714    112.07139  ]\n",
            "   [145.8622    150.8622    109.862206 ]\n",
            "   [146.12753   151.12753   110.12753  ]\n",
            "   ...\n",
            "   [156.71426   154.44383   117.285736 ]\n",
            "   [154.07138   151.07138   117.93876  ]\n",
            "   [152.21426   149.21426   116.35715  ]]\n",
            "\n",
            "  [[139.6429    146.6429    104.64289  ]\n",
            "   [138.47452   145.47452   103.474525 ]\n",
            "   [140.        147.        105.       ]\n",
            "   ...\n",
            "   [154.70917   151.70917   117.29083  ]\n",
            "   [153.0459    150.0459    118.954094 ]\n",
            "   [152.30112   148.30112   119.30112  ]]]\n",
            "\n",
            "\n",
            " [[[164.60715   133.60715    76.60714  ]\n",
            "   [162.93367   131.93367    76.841835 ]\n",
            "   [159.88776   126.168365   76.04082  ]\n",
            "   ...\n",
            "   [ 84.21437    21.214373   12.214373 ]\n",
            "   [ 83.5306     21.739813   12.336744 ]\n",
            "   [ 85.74494    25.744944   15.744943 ]]\n",
            "\n",
            "  [[169.94388   139.94388    77.42347  ]\n",
            "   [167.7653    137.69897    77.765305 ]\n",
            "   [161.63774   127.994896   74.5102   ]\n",
            "   ...\n",
            "   [ 84.413315   20.413311   11.413311 ]\n",
            "   [ 90.306046   26.443815   17.443815 ]\n",
            "   [ 89.54616    25.949253   16.949253 ]]\n",
            "\n",
            "  [[167.36224   138.14795    69.71939  ]\n",
            "   [165.15816   134.15816    69.85714  ]\n",
            "   [166.19388   133.55103    75.19388  ]\n",
            "   ...\n",
            "   [ 90.59696    23.168394   15.38268  ]\n",
            "   [ 96.831604   29.40303    21.617315 ]\n",
            "   [ 94.97967    27.551094   19.76538  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[242.56633   218.56633   182.99486  ]\n",
            "   [240.15816   216.15816   182.04591  ]\n",
            "   [239.78572   214.78572   183.95409  ]\n",
            "   ...\n",
            "   [203.29596   148.7756     74.607254 ]\n",
            "   [189.51527   139.65816    69.44389  ]\n",
            "   [216.13792   171.2808    109.85224  ]]\n",
            "\n",
            "  [[241.26529   217.26529   179.26529  ]\n",
            "   [239.92346   215.92346   179.92346  ]\n",
            "   [238.0153    213.0153    182.22958  ]\n",
            "   ...\n",
            "   [188.41856   142.82162    69.418434 ]\n",
            "   [186.40823   136.54091    63.47457  ]\n",
            "   [202.81104   153.7396     86.928375 ]]\n",
            "\n",
            "  [[238.71425   215.71425   174.71425  ]\n",
            "   [238.83163   214.83163   178.68878  ]\n",
            "   [238.29082   213.21428   182.65819  ]\n",
            "   ...\n",
            "   [177.23979   136.52042    65.7448   ]\n",
            "   [187.16325   139.09181    63.09182  ]\n",
            "   [186.58183   133.22466    62.765457 ]]]\n",
            "\n",
            "\n",
            " [[[ 34.571426   32.571426   35.571426 ]\n",
            "   [ 32.668365   30.668367   33.668365 ]\n",
            "   [ 24.         22.         25.       ]\n",
            "   ...\n",
            "   [ 12.137741   16.137741   19.137741 ]\n",
            "   [  8.81119    12.81119    15.81119  ]\n",
            "   [  5.999965    6.999965   10.999965 ]]\n",
            "\n",
            "  [[ 14.42857    12.42857    15.42857  ]\n",
            "   [ 12.499998   10.499998   13.499998 ]\n",
            "   [ 11.183673    9.183673   12.183673 ]\n",
            "   ...\n",
            "   [ 14.484652   15.484652   19.484652 ]\n",
            "   [  9.923455   10.923455   14.923455 ]\n",
            "   [  6.571394    7.571394   11.571394 ]]\n",
            "\n",
            "  [[ 12.         10.         15.       ]\n",
            "   [ 12.198979   10.198979   15.198979 ]\n",
            "   [ 13.         11.         16.       ]\n",
            "   ...\n",
            "   [ 14.596922   13.42855    18.42855  ]\n",
            "   [ 12.142844   10.928558   15.928558 ]\n",
            "   [ 11.214286   10.         15.       ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[153.56651   153.78078   145.78078  ]\n",
            "   [145.07124   144.49977   138.85698  ]\n",
            "   [ 28.606323   27.988935   24.249159 ]\n",
            "   ...\n",
            "   [114.50537   100.36243    79.57669  ]\n",
            "   [135.41832   117.48975    93.34687  ]\n",
            "   [150.54109   130.61763   103.38803  ]]\n",
            "\n",
            "  [[156.9386    155.9386    150.9386   ]\n",
            "   [ 57.12193    56.12193    51.188267 ]\n",
            "   [ 14.148013   12.933727   11.576585 ]\n",
            "   ...\n",
            "   [104.33175    91.8062     73.00516  ]\n",
            "   [139.02042   122.95408    98.02042  ]\n",
            "   [143.88747   124.025246   98.97932  ]]\n",
            "\n",
            "  [[ 94.34073    93.34073    88.34073  ]\n",
            "   [ 11.398155   10.398155    6.398155 ]\n",
            "   [ 14.887555   13.673269   12.316127 ]\n",
            "   ...\n",
            "   [117.13857   105.20989    86.77119  ]\n",
            "   [135.44434   119.444336   96.30145  ]\n",
            "   [139.78046   122.78046    96.78046  ]]]], shape=(32, 224, 224, 3), dtype=float32) tf.Tensor(\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]], shape=(32, 10), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# See an example of a batch of data\n",
        "for images, labels in train_data_10_percent.take(1):\n",
        "  print(images, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPVMA2tT3tqk"
      },
      "source": [
        "Notice how the image arrays come out as tensors of pixel values where as the labels come out as one-hot encodings (e.g. `[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]` for `hamburger`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnJ7x3S24ZoI"
      },
      "source": [
        "### Model 0: Building a transfer learning model using the Keras Functional API\n",
        "\n",
        "Alright, our data is tensor-ified, let's build a model.\n",
        "\n",
        "To do so we're going to be using the [`tf.keras.applications`](https://www.tensorflow.org/api_docs/python/tf/keras/applications) module as it contains a series of already trained (on ImageNet) computer vision models as well as the Keras Functional API to construct our model.\n",
        "\n",
        "We're going to go through the following steps:\n",
        "\n",
        "1. Instantiate a pre-trained base model object by choosing a target model such as [`EfficientNetB0`](https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0) from `tf.keras.applications`, setting the `include_top` parameter to `False` (we do this because we're going to create our own top, which are the output layers for the model).\n",
        "2. Set the base model's `trainable` attribute to `False` to freeze all of the weights in the pre-trained model.\n",
        "3. Define an input layer for our model, for example, what shape of data should our model expect?\n",
        "4. [Optional] Normalize the inputs to our model if it requires. Some computer vision models such as `ResNetV250` require their inputs to be between 0 & 1. \n",
        "\n",
        "> ðŸ¤” **Note:** As of writing, the `EfficientNet` models in the `tf.keras.applications` module do not require images to be normalized (pixel values between 0 and 1) on input, where as many of the other models do. I posted [an issue to the TensorFlow GitHub](https://github.com/tensorflow/tensorflow/issues/42506) about this and they confirmed this. \n",
        "\n",
        "5. Pass the inputs to the base model.\n",
        "6. Pool the outputs of the base model into a shape compatible with the output activation layer (turn base model output tensors into same shape as label tensors). This can be done using [`tf.keras.layers.GlobalAveragePooling2D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D) or [`tf.keras.layers.GlobalMaxPooling2D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool2D?hl=en) though the former is more common in practice.\n",
        "7. Create an output activation layer using `tf.keras.layers.Dense()` with the appropriate activation function and number of neurons.\n",
        "8. Combine the inputs and outputs layer into a model using [`tf.keras.Model()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model).\n",
        "9. Compile the model using the appropriate loss function and choose of optimizer.\n",
        "10. Fit the model for desired number of epochs and with necessary callbacks (in our case, we'll start off with the TensorBoard callback).\n",
        "\n",
        "Woah... that sounds like a lot. Before we get ahead of ourselves, let's see it in practice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aM06aaZ44Fn",
        "outputId": "075a59b9-3b8c-47ae-d86e-fbafc7058da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "16719872/16705208 [==============================] - 0s 0us/step\n",
            "Shape after base_model: (None, 7, 7, 1280)\n",
            "After GlobalAveragePooling2D(): (None, 1280)\n",
            "Saving TensorBoard log files to: transfer_learning/10_percent_feature_extract/20220105-155229\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 89s 3s/step - loss: 1.9352 - accuracy: 0.3947 - val_loss: 1.3925 - val_accuracy: 0.6875\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 79s 3s/step - loss: 1.1611 - accuracy: 0.7400 - val_loss: 0.9725 - val_accuracy: 0.7714\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 79s 3s/step - loss: 0.8606 - accuracy: 0.8053 - val_loss: 0.7736 - val_accuracy: 0.8109\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 72s 3s/step - loss: 0.6920 - accuracy: 0.8307 - val_loss: 0.6893 - val_accuracy: 0.8257\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 81s 3s/step - loss: 0.6085 - accuracy: 0.8640 - val_loss: 0.6204 - val_accuracy: 0.8405\n"
          ]
        }
      ],
      "source": [
        "# 1. Create base model with tf.keras.applications\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "# 2. Freeze the base model (so the pre-learned patterns remain)\n",
        "base_model.trainable = False\n",
        "\n",
        "# 3. Create inputs into the base model\n",
        "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
        "\n",
        "# 4. If using model like ResNet50V2, add this to speed up convergence, remove for EfficientNet\n",
        "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
        "\n",
        "# 5. Pass the inputs to the base_model (note: using tf.keras.applications, EfficientNet inputs don't have to be normalized)\n",
        "x = base_model(inputs)\n",
        "# Check data shape after passing it to base_model\n",
        "print(f\"Shape after base_model: {x.shape}\")\n",
        "\n",
        "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce number of computations)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x) # x in the end - functional API design\n",
        "print(f\"After GlobalAveragePooling2D(): {x.shape}\")\n",
        "\n",
        "# 7. Create the output activation layer\n",
        "outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "# 8. Combine the inputs with the outputs into a model\n",
        "model_0 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 9. Compile the model\n",
        "model_0.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# 10. Fit the model (we use less steps for validation so it's faster)\n",
        "history_10_percent = model_0.fit(train_data_10_percent,\n",
        "                                 epochs=5,\n",
        "                                 steps_per_epoch=len(train_data_10_percent),\n",
        "                                 validation_data=test_data,\n",
        "                                 # Go through less of the validation data so epochs are faster (we want faster experiments!)\n",
        "                                 validation_steps=int(0.25 * len(test_data)), \n",
        "                                 # Track our model's training logs for visualization later\n",
        "                                 callbacks=[create_tensorboard_callback(\"transfer_learning\", \"10_percent_feature_extract\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OhNi0wnLKZll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ebfeb08-ca2b-4456-e830-d4151fa81f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 133s 2s/step - loss: 0.6238 - accuracy: 0.8348\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6237794160842896, 0.8348000049591064]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Evaluate on the full test ds\n",
        "model_0.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qtt5WCrcQvng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c3e7c9-da77-4be8-a6db-827d179409f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_1\n",
            "1 rescaling\n",
            "2 normalization\n",
            "3 stem_conv_pad\n",
            "4 stem_conv\n",
            "5 stem_bn\n",
            "6 stem_activation\n",
            "7 block1a_dwconv\n",
            "8 block1a_bn\n",
            "9 block1a_activation\n",
            "10 block1a_se_squeeze\n",
            "11 block1a_se_reshape\n",
            "12 block1a_se_reduce\n",
            "13 block1a_se_expand\n",
            "14 block1a_se_excite\n",
            "15 block1a_project_conv\n",
            "16 block1a_project_bn\n",
            "17 block2a_expand_conv\n",
            "18 block2a_expand_bn\n",
            "19 block2a_expand_activation\n",
            "20 block2a_dwconv_pad\n",
            "21 block2a_dwconv\n",
            "22 block2a_bn\n",
            "23 block2a_activation\n",
            "24 block2a_se_squeeze\n",
            "25 block2a_se_reshape\n",
            "26 block2a_se_reduce\n",
            "27 block2a_se_expand\n",
            "28 block2a_se_excite\n",
            "29 block2a_project_conv\n",
            "30 block2a_project_bn\n",
            "31 block2b_expand_conv\n",
            "32 block2b_expand_bn\n",
            "33 block2b_expand_activation\n",
            "34 block2b_dwconv\n",
            "35 block2b_bn\n",
            "36 block2b_activation\n",
            "37 block2b_se_squeeze\n",
            "38 block2b_se_reshape\n",
            "39 block2b_se_reduce\n",
            "40 block2b_se_expand\n",
            "41 block2b_se_excite\n",
            "42 block2b_project_conv\n",
            "43 block2b_project_bn\n",
            "44 block2b_drop\n",
            "45 block2b_add\n",
            "46 block3a_expand_conv\n",
            "47 block3a_expand_bn\n",
            "48 block3a_expand_activation\n",
            "49 block3a_dwconv_pad\n",
            "50 block3a_dwconv\n",
            "51 block3a_bn\n",
            "52 block3a_activation\n",
            "53 block3a_se_squeeze\n",
            "54 block3a_se_reshape\n",
            "55 block3a_se_reduce\n",
            "56 block3a_se_expand\n",
            "57 block3a_se_excite\n",
            "58 block3a_project_conv\n",
            "59 block3a_project_bn\n",
            "60 block3b_expand_conv\n",
            "61 block3b_expand_bn\n",
            "62 block3b_expand_activation\n",
            "63 block3b_dwconv\n",
            "64 block3b_bn\n",
            "65 block3b_activation\n",
            "66 block3b_se_squeeze\n",
            "67 block3b_se_reshape\n",
            "68 block3b_se_reduce\n",
            "69 block3b_se_expand\n",
            "70 block3b_se_excite\n",
            "71 block3b_project_conv\n",
            "72 block3b_project_bn\n",
            "73 block3b_drop\n",
            "74 block3b_add\n",
            "75 block4a_expand_conv\n",
            "76 block4a_expand_bn\n",
            "77 block4a_expand_activation\n",
            "78 block4a_dwconv_pad\n",
            "79 block4a_dwconv\n",
            "80 block4a_bn\n",
            "81 block4a_activation\n",
            "82 block4a_se_squeeze\n",
            "83 block4a_se_reshape\n",
            "84 block4a_se_reduce\n",
            "85 block4a_se_expand\n",
            "86 block4a_se_excite\n",
            "87 block4a_project_conv\n",
            "88 block4a_project_bn\n",
            "89 block4b_expand_conv\n",
            "90 block4b_expand_bn\n",
            "91 block4b_expand_activation\n",
            "92 block4b_dwconv\n",
            "93 block4b_bn\n",
            "94 block4b_activation\n",
            "95 block4b_se_squeeze\n",
            "96 block4b_se_reshape\n",
            "97 block4b_se_reduce\n",
            "98 block4b_se_expand\n",
            "99 block4b_se_excite\n",
            "100 block4b_project_conv\n",
            "101 block4b_project_bn\n",
            "102 block4b_drop\n",
            "103 block4b_add\n",
            "104 block4c_expand_conv\n",
            "105 block4c_expand_bn\n",
            "106 block4c_expand_activation\n",
            "107 block4c_dwconv\n",
            "108 block4c_bn\n",
            "109 block4c_activation\n",
            "110 block4c_se_squeeze\n",
            "111 block4c_se_reshape\n",
            "112 block4c_se_reduce\n",
            "113 block4c_se_expand\n",
            "114 block4c_se_excite\n",
            "115 block4c_project_conv\n",
            "116 block4c_project_bn\n",
            "117 block4c_drop\n",
            "118 block4c_add\n",
            "119 block5a_expand_conv\n",
            "120 block5a_expand_bn\n",
            "121 block5a_expand_activation\n",
            "122 block5a_dwconv\n",
            "123 block5a_bn\n",
            "124 block5a_activation\n",
            "125 block5a_se_squeeze\n",
            "126 block5a_se_reshape\n",
            "127 block5a_se_reduce\n",
            "128 block5a_se_expand\n",
            "129 block5a_se_excite\n",
            "130 block5a_project_conv\n",
            "131 block5a_project_bn\n",
            "132 block5b_expand_conv\n",
            "133 block5b_expand_bn\n",
            "134 block5b_expand_activation\n",
            "135 block5b_dwconv\n",
            "136 block5b_bn\n",
            "137 block5b_activation\n",
            "138 block5b_se_squeeze\n",
            "139 block5b_se_reshape\n",
            "140 block5b_se_reduce\n",
            "141 block5b_se_expand\n",
            "142 block5b_se_excite\n",
            "143 block5b_project_conv\n",
            "144 block5b_project_bn\n",
            "145 block5b_drop\n",
            "146 block5b_add\n",
            "147 block5c_expand_conv\n",
            "148 block5c_expand_bn\n",
            "149 block5c_expand_activation\n",
            "150 block5c_dwconv\n",
            "151 block5c_bn\n",
            "152 block5c_activation\n",
            "153 block5c_se_squeeze\n",
            "154 block5c_se_reshape\n",
            "155 block5c_se_reduce\n",
            "156 block5c_se_expand\n",
            "157 block5c_se_excite\n",
            "158 block5c_project_conv\n",
            "159 block5c_project_bn\n",
            "160 block5c_drop\n",
            "161 block5c_add\n",
            "162 block6a_expand_conv\n",
            "163 block6a_expand_bn\n",
            "164 block6a_expand_activation\n",
            "165 block6a_dwconv_pad\n",
            "166 block6a_dwconv\n",
            "167 block6a_bn\n",
            "168 block6a_activation\n",
            "169 block6a_se_squeeze\n",
            "170 block6a_se_reshape\n",
            "171 block6a_se_reduce\n",
            "172 block6a_se_expand\n",
            "173 block6a_se_excite\n",
            "174 block6a_project_conv\n",
            "175 block6a_project_bn\n",
            "176 block6b_expand_conv\n",
            "177 block6b_expand_bn\n",
            "178 block6b_expand_activation\n",
            "179 block6b_dwconv\n",
            "180 block6b_bn\n",
            "181 block6b_activation\n",
            "182 block6b_se_squeeze\n",
            "183 block6b_se_reshape\n",
            "184 block6b_se_reduce\n",
            "185 block6b_se_expand\n",
            "186 block6b_se_excite\n",
            "187 block6b_project_conv\n",
            "188 block6b_project_bn\n",
            "189 block6b_drop\n",
            "190 block6b_add\n",
            "191 block6c_expand_conv\n",
            "192 block6c_expand_bn\n",
            "193 block6c_expand_activation\n",
            "194 block6c_dwconv\n",
            "195 block6c_bn\n",
            "196 block6c_activation\n",
            "197 block6c_se_squeeze\n",
            "198 block6c_se_reshape\n",
            "199 block6c_se_reduce\n",
            "200 block6c_se_expand\n",
            "201 block6c_se_excite\n",
            "202 block6c_project_conv\n",
            "203 block6c_project_bn\n",
            "204 block6c_drop\n",
            "205 block6c_add\n",
            "206 block6d_expand_conv\n",
            "207 block6d_expand_bn\n",
            "208 block6d_expand_activation\n",
            "209 block6d_dwconv\n",
            "210 block6d_bn\n",
            "211 block6d_activation\n",
            "212 block6d_se_squeeze\n",
            "213 block6d_se_reshape\n",
            "214 block6d_se_reduce\n",
            "215 block6d_se_expand\n",
            "216 block6d_se_excite\n",
            "217 block6d_project_conv\n",
            "218 block6d_project_bn\n",
            "219 block6d_drop\n",
            "220 block6d_add\n",
            "221 block7a_expand_conv\n",
            "222 block7a_expand_bn\n",
            "223 block7a_expand_activation\n",
            "224 block7a_dwconv\n",
            "225 block7a_bn\n",
            "226 block7a_activation\n",
            "227 block7a_se_squeeze\n",
            "228 block7a_se_reshape\n",
            "229 block7a_se_reduce\n",
            "230 block7a_se_expand\n",
            "231 block7a_se_excite\n",
            "232 block7a_project_conv\n",
            "233 block7a_project_bn\n",
            "234 top_conv\n",
            "235 top_bn\n",
            "236 top_activation\n"
          ]
        }
      ],
      "source": [
        "# Check layers in our base model\n",
        "for layer_number, layer in enumerate(base_model.layers):\n",
        "  print(layer_number, layer.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8rliOxsOQ_z2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b52d4b-99f2-401a-92fe-d065f7b278cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnetb0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
            "                                 3)]                                                              \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, None, None,   0           ['input_1[0][0]']                \n",
            "                                3)                                                                \n",
            "                                                                                                  \n",
            " normalization (Normalization)  (None, None, None,   7           ['rescaling[0][0]']              \n",
            "                                3)                                                                \n",
            "                                                                                                  \n",
            " stem_conv_pad (ZeroPadding2D)  (None, None, None,   0           ['normalization[0][0]']          \n",
            "                                3)                                                                \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)             (None, None, None,   864         ['stem_conv_pad[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalization)   (None, None, None,   128         ['stem_conv[0][0]']              \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " stem_activation (Activation)   (None, None, None,   0           ['stem_bn[0][0]']                \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " block1a_dwconv (DepthwiseConv2  (None, None, None,   288        ['stem_activation[0][0]']        \n",
            " D)                             32)                                                               \n",
            "                                                                                                  \n",
            " block1a_bn (BatchNormalization  (None, None, None,   128        ['block1a_dwconv[0][0]']         \n",
            " )                              32)                                                               \n",
            "                                                                                                  \n",
            " block1a_activation (Activation  (None, None, None,   0          ['block1a_bn[0][0]']             \n",
            " )                              32)                                                               \n",
            "                                                                                                  \n",
            " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_se_excite (Multiply)   (None, None, None,   0           ['block1a_activation[0][0]',     \n",
            "                                32)                               'block1a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_project_conv (Conv2D)  (None, None, None,   512         ['block1a_se_excite[0][0]']      \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " block1a_project_bn (BatchNorma  (None, None, None,   64         ['block1a_project_conv[0][0]']   \n",
            " lization)                      16)                                                               \n",
            "                                                                                                  \n",
            " block2a_expand_conv (Conv2D)   (None, None, None,   1536        ['block1a_project_bn[0][0]']     \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " block2a_expand_bn (BatchNormal  (None, None, None,   384        ['block2a_expand_conv[0][0]']    \n",
            " ization)                       96)                                                               \n",
            "                                                                                                  \n",
            " block2a_expand_activation (Act  (None, None, None,   0          ['block2a_expand_bn[0][0]']      \n",
            " ivation)                       96)                                                               \n",
            "                                                                                                  \n",
            " block2a_dwconv_pad (ZeroPaddin  (None, None, None,   0          ['block2a_expand_activation[0][0]\n",
            " g2D)                           96)                              ']                               \n",
            "                                                                                                  \n",
            " block2a_dwconv (DepthwiseConv2  (None, None, None,   864        ['block2a_dwconv_pad[0][0]']     \n",
            " D)                             96)                                                               \n",
            "                                                                                                  \n",
            " block2a_bn (BatchNormalization  (None, None, None,   384        ['block2a_dwconv[0][0]']         \n",
            " )                              96)                                                               \n",
            "                                                                                                  \n",
            " block2a_activation (Activation  (None, None, None,   0          ['block2a_bn[0][0]']             \n",
            " )                              96)                                                               \n",
            "                                                                                                  \n",
            " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_se_excite (Multiply)   (None, None, None,   0           ['block2a_activation[0][0]',     \n",
            "                                96)                               'block2a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_project_conv (Conv2D)  (None, None, None,   2304        ['block2a_se_excite[0][0]']      \n",
            "                                24)                                                               \n",
            "                                                                                                  \n",
            " block2a_project_bn (BatchNorma  (None, None, None,   96         ['block2a_project_conv[0][0]']   \n",
            " lization)                      24)                                                               \n",
            "                                                                                                  \n",
            " block2b_expand_conv (Conv2D)   (None, None, None,   3456        ['block2a_project_bn[0][0]']     \n",
            "                                144)                                                              \n",
            "                                                                                                  \n",
            " block2b_expand_bn (BatchNormal  (None, None, None,   576        ['block2b_expand_conv[0][0]']    \n",
            " ization)                       144)                                                              \n",
            "                                                                                                  \n",
            " block2b_expand_activation (Act  (None, None, None,   0          ['block2b_expand_bn[0][0]']      \n",
            " ivation)                       144)                                                              \n",
            "                                                                                                  \n",
            " block2b_dwconv (DepthwiseConv2  (None, None, None,   1296       ['block2b_expand_activation[0][0]\n",
            " D)                             144)                             ']                               \n",
            "                                                                                                  \n",
            " block2b_bn (BatchNormalization  (None, None, None,   576        ['block2b_dwconv[0][0]']         \n",
            " )                              144)                                                              \n",
            "                                                                                                  \n",
            " block2b_activation (Activation  (None, None, None,   0          ['block2b_bn[0][0]']             \n",
            " )                              144)                                                              \n",
            "                                                                                                  \n",
            " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_se_excite (Multiply)   (None, None, None,   0           ['block2b_activation[0][0]',     \n",
            "                                144)                              'block2b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_conv (Conv2D)  (None, None, None,   3456        ['block2b_se_excite[0][0]']      \n",
            "                                24)                                                               \n",
            "                                                                                                  \n",
            " block2b_project_bn (BatchNorma  (None, None, None,   96         ['block2b_project_conv[0][0]']   \n",
            " lization)                      24)                                                               \n",
            "                                                                                                  \n",
            " block2b_drop (Dropout)         (None, None, None,   0           ['block2b_project_bn[0][0]']     \n",
            "                                24)                                                               \n",
            "                                                                                                  \n",
            " block2b_add (Add)              (None, None, None,   0           ['block2b_drop[0][0]',           \n",
            "                                24)                               'block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_expand_conv (Conv2D)   (None, None, None,   3456        ['block2b_add[0][0]']            \n",
            "                                144)                                                              \n",
            "                                                                                                  \n",
            " block3a_expand_bn (BatchNormal  (None, None, None,   576        ['block3a_expand_conv[0][0]']    \n",
            " ization)                       144)                                                              \n",
            "                                                                                                  \n",
            " block3a_expand_activation (Act  (None, None, None,   0          ['block3a_expand_bn[0][0]']      \n",
            " ivation)                       144)                                                              \n",
            "                                                                                                  \n",
            " block3a_dwconv_pad (ZeroPaddin  (None, None, None,   0          ['block3a_expand_activation[0][0]\n",
            " g2D)                           144)                             ']                               \n",
            "                                                                                                  \n",
            " block3a_dwconv (DepthwiseConv2  (None, None, None,   3600       ['block3a_dwconv_pad[0][0]']     \n",
            " D)                             144)                                                              \n",
            "                                                                                                  \n",
            " block3a_bn (BatchNormalization  (None, None, None,   576        ['block3a_dwconv[0][0]']         \n",
            " )                              144)                                                              \n",
            "                                                                                                  \n",
            " block3a_activation (Activation  (None, None, None,   0          ['block3a_bn[0][0]']             \n",
            " )                              144)                                                              \n",
            "                                                                                                  \n",
            " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_se_excite (Multiply)   (None, None, None,   0           ['block3a_activation[0][0]',     \n",
            "                                144)                              'block3a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_conv (Conv2D)  (None, None, None,   5760        ['block3a_se_excite[0][0]']      \n",
            "                                40)                                                               \n",
            "                                                                                                  \n",
            " block3a_project_bn (BatchNorma  (None, None, None,   160        ['block3a_project_conv[0][0]']   \n",
            " lization)                      40)                                                               \n",
            "                                                                                                  \n",
            " block3b_expand_conv (Conv2D)   (None, None, None,   9600        ['block3a_project_bn[0][0]']     \n",
            "                                240)                                                              \n",
            "                                                                                                  \n",
            " block3b_expand_bn (BatchNormal  (None, None, None,   960        ['block3b_expand_conv[0][0]']    \n",
            " ization)                       240)                                                              \n",
            "                                                                                                  \n",
            " block3b_expand_activation (Act  (None, None, None,   0          ['block3b_expand_bn[0][0]']      \n",
            " ivation)                       240)                                                              \n",
            "                                                                                                  \n",
            " block3b_dwconv (DepthwiseConv2  (None, None, None,   6000       ['block3b_expand_activation[0][0]\n",
            " D)                             240)                             ']                               \n",
            "                                                                                                  \n",
            " block3b_bn (BatchNormalization  (None, None, None,   960        ['block3b_dwconv[0][0]']         \n",
            " )                              240)                                                              \n",
            "                                                                                                  \n",
            " block3b_activation (Activation  (None, None, None,   0          ['block3b_bn[0][0]']             \n",
            " )                              240)                                                              \n",
            "                                                                                                  \n",
            " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_se_excite (Multiply)   (None, None, None,   0           ['block3b_activation[0][0]',     \n",
            "                                240)                              'block3b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_conv (Conv2D)  (None, None, None,   9600        ['block3b_se_excite[0][0]']      \n",
            "                                40)                                                               \n",
            "                                                                                                  \n",
            " block3b_project_bn (BatchNorma  (None, None, None,   160        ['block3b_project_conv[0][0]']   \n",
            " lization)                      40)                                                               \n",
            "                                                                                                  \n",
            " block3b_drop (Dropout)         (None, None, None,   0           ['block3b_project_bn[0][0]']     \n",
            "                                40)                                                               \n",
            "                                                                                                  \n",
            " block3b_add (Add)              (None, None, None,   0           ['block3b_drop[0][0]',           \n",
            "                                40)                               'block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_expand_conv (Conv2D)   (None, None, None,   9600        ['block3b_add[0][0]']            \n",
            "                                240)                                                              \n",
            "                                                                                                  \n",
            " block4a_expand_bn (BatchNormal  (None, None, None,   960        ['block4a_expand_conv[0][0]']    \n",
            " ization)                       240)                                                              \n",
            "                                                                                                  \n",
            " block4a_expand_activation (Act  (None, None, None,   0          ['block4a_expand_bn[0][0]']      \n",
            " ivation)                       240)                                                              \n",
            "                                                                                                  \n",
            " block4a_dwconv_pad (ZeroPaddin  (None, None, None,   0          ['block4a_expand_activation[0][0]\n",
            " g2D)                           240)                             ']                               \n",
            "                                                                                                  \n",
            " block4a_dwconv (DepthwiseConv2  (None, None, None,   2160       ['block4a_dwconv_pad[0][0]']     \n",
            " D)                             240)                                                              \n",
            "                                                                                                  \n",
            " block4a_bn (BatchNormalization  (None, None, None,   960        ['block4a_dwconv[0][0]']         \n",
            " )                              240)                                                              \n",
            "                                                                                                  \n",
            " block4a_activation (Activation  (None, None, None,   0          ['block4a_bn[0][0]']             \n",
            " )                              240)                                                              \n",
            "                                                                                                  \n",
            " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_se_excite (Multiply)   (None, None, None,   0           ['block4a_activation[0][0]',     \n",
            "                                240)                              'block4a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_conv (Conv2D)  (None, None, None,   19200       ['block4a_se_excite[0][0]']      \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4a_project_bn (BatchNorma  (None, None, None,   320        ['block4a_project_conv[0][0]']   \n",
            " lization)                      80)                                                               \n",
            "                                                                                                  \n",
            " block4b_expand_conv (Conv2D)   (None, None, None,   38400       ['block4a_project_bn[0][0]']     \n",
            "                                480)                                                              \n",
            "                                                                                                  \n",
            " block4b_expand_bn (BatchNormal  (None, None, None,   1920       ['block4b_expand_conv[0][0]']    \n",
            " ization)                       480)                                                              \n",
            "                                                                                                  \n",
            " block4b_expand_activation (Act  (None, None, None,   0          ['block4b_expand_bn[0][0]']      \n",
            " ivation)                       480)                                                              \n",
            "                                                                                                  \n",
            " block4b_dwconv (DepthwiseConv2  (None, None, None,   4320       ['block4b_expand_activation[0][0]\n",
            " D)                             480)                             ']                               \n",
            "                                                                                                  \n",
            " block4b_bn (BatchNormalization  (None, None, None,   1920       ['block4b_dwconv[0][0]']         \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block4b_activation (Activation  (None, None, None,   0          ['block4b_bn[0][0]']             \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_se_excite (Multiply)   (None, None, None,   0           ['block4b_activation[0][0]',     \n",
            "                                480)                              'block4b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_conv (Conv2D)  (None, None, None,   38400       ['block4b_se_excite[0][0]']      \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4b_project_bn (BatchNorma  (None, None, None,   320        ['block4b_project_conv[0][0]']   \n",
            " lization)                      80)                                                               \n",
            "                                                                                                  \n",
            " block4b_drop (Dropout)         (None, None, None,   0           ['block4b_project_bn[0][0]']     \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4b_add (Add)              (None, None, None,   0           ['block4b_drop[0][0]',           \n",
            "                                80)                               'block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_expand_conv (Conv2D)   (None, None, None,   38400       ['block4b_add[0][0]']            \n",
            "                                480)                                                              \n",
            "                                                                                                  \n",
            " block4c_expand_bn (BatchNormal  (None, None, None,   1920       ['block4c_expand_conv[0][0]']    \n",
            " ization)                       480)                                                              \n",
            "                                                                                                  \n",
            " block4c_expand_activation (Act  (None, None, None,   0          ['block4c_expand_bn[0][0]']      \n",
            " ivation)                       480)                                                              \n",
            "                                                                                                  \n",
            " block4c_dwconv (DepthwiseConv2  (None, None, None,   4320       ['block4c_expand_activation[0][0]\n",
            " D)                             480)                             ']                               \n",
            "                                                                                                  \n",
            " block4c_bn (BatchNormalization  (None, None, None,   1920       ['block4c_dwconv[0][0]']         \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block4c_activation (Activation  (None, None, None,   0          ['block4c_bn[0][0]']             \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_se_excite (Multiply)   (None, None, None,   0           ['block4c_activation[0][0]',     \n",
            "                                480)                              'block4c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_conv (Conv2D)  (None, None, None,   38400       ['block4c_se_excite[0][0]']      \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4c_project_bn (BatchNorma  (None, None, None,   320        ['block4c_project_conv[0][0]']   \n",
            " lization)                      80)                                                               \n",
            "                                                                                                  \n",
            " block4c_drop (Dropout)         (None, None, None,   0           ['block4c_project_bn[0][0]']     \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4c_add (Add)              (None, None, None,   0           ['block4c_drop[0][0]',           \n",
            "                                80)                               'block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_conv (Conv2D)   (None, None, None,   38400       ['block4c_add[0][0]']            \n",
            "                                480)                                                              \n",
            "                                                                                                  \n",
            " block5a_expand_bn (BatchNormal  (None, None, None,   1920       ['block5a_expand_conv[0][0]']    \n",
            " ization)                       480)                                                              \n",
            "                                                                                                  \n",
            " block5a_expand_activation (Act  (None, None, None,   0          ['block5a_expand_bn[0][0]']      \n",
            " ivation)                       480)                                                              \n",
            "                                                                                                  \n",
            " block5a_dwconv (DepthwiseConv2  (None, None, None,   12000      ['block5a_expand_activation[0][0]\n",
            " D)                             480)                             ']                               \n",
            "                                                                                                  \n",
            " block5a_bn (BatchNormalization  (None, None, None,   1920       ['block5a_dwconv[0][0]']         \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block5a_activation (Activation  (None, None, None,   0          ['block5a_bn[0][0]']             \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_se_excite (Multiply)   (None, None, None,   0           ['block5a_activation[0][0]',     \n",
            "                                480)                              'block5a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_conv (Conv2D)  (None, None, None,   53760       ['block5a_se_excite[0][0]']      \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5a_project_bn (BatchNorma  (None, None, None,   448        ['block5a_project_conv[0][0]']   \n",
            " lization)                      112)                                                              \n",
            "                                                                                                  \n",
            " block5b_expand_conv (Conv2D)   (None, None, None,   75264       ['block5a_project_bn[0][0]']     \n",
            "                                672)                                                              \n",
            "                                                                                                  \n",
            " block5b_expand_bn (BatchNormal  (None, None, None,   2688       ['block5b_expand_conv[0][0]']    \n",
            " ization)                       672)                                                              \n",
            "                                                                                                  \n",
            " block5b_expand_activation (Act  (None, None, None,   0          ['block5b_expand_bn[0][0]']      \n",
            " ivation)                       672)                                                              \n",
            "                                                                                                  \n",
            " block5b_dwconv (DepthwiseConv2  (None, None, None,   16800      ['block5b_expand_activation[0][0]\n",
            " D)                             672)                             ']                               \n",
            "                                                                                                  \n",
            " block5b_bn (BatchNormalization  (None, None, None,   2688       ['block5b_dwconv[0][0]']         \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block5b_activation (Activation  (None, None, None,   0          ['block5b_bn[0][0]']             \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_se_excite (Multiply)   (None, None, None,   0           ['block5b_activation[0][0]',     \n",
            "                                672)                              'block5b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_conv (Conv2D)  (None, None, None,   75264       ['block5b_se_excite[0][0]']      \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5b_project_bn (BatchNorma  (None, None, None,   448        ['block5b_project_conv[0][0]']   \n",
            " lization)                      112)                                                              \n",
            "                                                                                                  \n",
            " block5b_drop (Dropout)         (None, None, None,   0           ['block5b_project_bn[0][0]']     \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5b_add (Add)              (None, None, None,   0           ['block5b_drop[0][0]',           \n",
            "                                112)                              'block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_expand_conv (Conv2D)   (None, None, None,   75264       ['block5b_add[0][0]']            \n",
            "                                672)                                                              \n",
            "                                                                                                  \n",
            " block5c_expand_bn (BatchNormal  (None, None, None,   2688       ['block5c_expand_conv[0][0]']    \n",
            " ization)                       672)                                                              \n",
            "                                                                                                  \n",
            " block5c_expand_activation (Act  (None, None, None,   0          ['block5c_expand_bn[0][0]']      \n",
            " ivation)                       672)                                                              \n",
            "                                                                                                  \n",
            " block5c_dwconv (DepthwiseConv2  (None, None, None,   16800      ['block5c_expand_activation[0][0]\n",
            " D)                             672)                             ']                               \n",
            "                                                                                                  \n",
            " block5c_bn (BatchNormalization  (None, None, None,   2688       ['block5c_dwconv[0][0]']         \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block5c_activation (Activation  (None, None, None,   0          ['block5c_bn[0][0]']             \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_se_excite (Multiply)   (None, None, None,   0           ['block5c_activation[0][0]',     \n",
            "                                672)                              'block5c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_conv (Conv2D)  (None, None, None,   75264       ['block5c_se_excite[0][0]']      \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5c_project_bn (BatchNorma  (None, None, None,   448        ['block5c_project_conv[0][0]']   \n",
            " lization)                      112)                                                              \n",
            "                                                                                                  \n",
            " block5c_drop (Dropout)         (None, None, None,   0           ['block5c_project_bn[0][0]']     \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5c_add (Add)              (None, None, None,   0           ['block5c_drop[0][0]',           \n",
            "                                112)                              'block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_conv (Conv2D)   (None, None, None,   75264       ['block5c_add[0][0]']            \n",
            "                                672)                                                              \n",
            "                                                                                                  \n",
            " block6a_expand_bn (BatchNormal  (None, None, None,   2688       ['block6a_expand_conv[0][0]']    \n",
            " ization)                       672)                                                              \n",
            "                                                                                                  \n",
            " block6a_expand_activation (Act  (None, None, None,   0          ['block6a_expand_bn[0][0]']      \n",
            " ivation)                       672)                                                              \n",
            "                                                                                                  \n",
            " block6a_dwconv_pad (ZeroPaddin  (None, None, None,   0          ['block6a_expand_activation[0][0]\n",
            " g2D)                           672)                             ']                               \n",
            "                                                                                                  \n",
            " block6a_dwconv (DepthwiseConv2  (None, None, None,   16800      ['block6a_dwconv_pad[0][0]']     \n",
            " D)                             672)                                                              \n",
            "                                                                                                  \n",
            " block6a_bn (BatchNormalization  (None, None, None,   2688       ['block6a_dwconv[0][0]']         \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block6a_activation (Activation  (None, None, None,   0          ['block6a_bn[0][0]']             \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_se_excite (Multiply)   (None, None, None,   0           ['block6a_activation[0][0]',     \n",
            "                                672)                              'block6a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_conv (Conv2D)  (None, None, None,   129024      ['block6a_se_excite[0][0]']      \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6a_project_bn (BatchNorma  (None, None, None,   768        ['block6a_project_conv[0][0]']   \n",
            " lization)                      192)                                                              \n",
            "                                                                                                  \n",
            " block6b_expand_conv (Conv2D)   (None, None, None,   221184      ['block6a_project_bn[0][0]']     \n",
            "                                1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_expand_bn (BatchNormal  (None, None, None,   4608       ['block6b_expand_conv[0][0]']    \n",
            " ization)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_expand_activation (Act  (None, None, None,   0          ['block6b_expand_bn[0][0]']      \n",
            " ivation)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_dwconv (DepthwiseConv2  (None, None, None,   28800      ['block6b_expand_activation[0][0]\n",
            " D)                             1152)                            ']                               \n",
            "                                                                                                  \n",
            " block6b_bn (BatchNormalization  (None, None, None,   4608       ['block6b_dwconv[0][0]']         \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_activation (Activation  (None, None, None,   0          ['block6b_bn[0][0]']             \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_se_excite (Multiply)   (None, None, None,   0           ['block6b_activation[0][0]',     \n",
            "                                1152)                             'block6b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_conv (Conv2D)  (None, None, None,   221184      ['block6b_se_excite[0][0]']      \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6b_project_bn (BatchNorma  (None, None, None,   768        ['block6b_project_conv[0][0]']   \n",
            " lization)                      192)                                                              \n",
            "                                                                                                  \n",
            " block6b_drop (Dropout)         (None, None, None,   0           ['block6b_project_bn[0][0]']     \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6b_add (Add)              (None, None, None,   0           ['block6b_drop[0][0]',           \n",
            "                                192)                              'block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_expand_conv (Conv2D)   (None, None, None,   221184      ['block6b_add[0][0]']            \n",
            "                                1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_expand_bn (BatchNormal  (None, None, None,   4608       ['block6c_expand_conv[0][0]']    \n",
            " ization)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_expand_activation (Act  (None, None, None,   0          ['block6c_expand_bn[0][0]']      \n",
            " ivation)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_dwconv (DepthwiseConv2  (None, None, None,   28800      ['block6c_expand_activation[0][0]\n",
            " D)                             1152)                            ']                               \n",
            "                                                                                                  \n",
            " block6c_bn (BatchNormalization  (None, None, None,   4608       ['block6c_dwconv[0][0]']         \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_activation (Activation  (None, None, None,   0          ['block6c_bn[0][0]']             \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_se_excite (Multiply)   (None, None, None,   0           ['block6c_activation[0][0]',     \n",
            "                                1152)                             'block6c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_conv (Conv2D)  (None, None, None,   221184      ['block6c_se_excite[0][0]']      \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6c_project_bn (BatchNorma  (None, None, None,   768        ['block6c_project_conv[0][0]']   \n",
            " lization)                      192)                                                              \n",
            "                                                                                                  \n",
            " block6c_drop (Dropout)         (None, None, None,   0           ['block6c_project_bn[0][0]']     \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6c_add (Add)              (None, None, None,   0           ['block6c_drop[0][0]',           \n",
            "                                192)                              'block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_conv (Conv2D)   (None, None, None,   221184      ['block6c_add[0][0]']            \n",
            "                                1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_expand_bn (BatchNormal  (None, None, None,   4608       ['block6d_expand_conv[0][0]']    \n",
            " ization)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_expand_activation (Act  (None, None, None,   0          ['block6d_expand_bn[0][0]']      \n",
            " ivation)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_dwconv (DepthwiseConv2  (None, None, None,   28800      ['block6d_expand_activation[0][0]\n",
            " D)                             1152)                            ']                               \n",
            "                                                                                                  \n",
            " block6d_bn (BatchNormalization  (None, None, None,   4608       ['block6d_dwconv[0][0]']         \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_activation (Activation  (None, None, None,   0          ['block6d_bn[0][0]']             \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_se_excite (Multiply)   (None, None, None,   0           ['block6d_activation[0][0]',     \n",
            "                                1152)                             'block6d_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_conv (Conv2D)  (None, None, None,   221184      ['block6d_se_excite[0][0]']      \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6d_project_bn (BatchNorma  (None, None, None,   768        ['block6d_project_conv[0][0]']   \n",
            " lization)                      192)                                                              \n",
            "                                                                                                  \n",
            " block6d_drop (Dropout)         (None, None, None,   0           ['block6d_project_bn[0][0]']     \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6d_add (Add)              (None, None, None,   0           ['block6d_drop[0][0]',           \n",
            "                                192)                              'block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_conv (Conv2D)   (None, None, None,   221184      ['block6d_add[0][0]']            \n",
            "                                1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_expand_bn (BatchNormal  (None, None, None,   4608       ['block7a_expand_conv[0][0]']    \n",
            " ization)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_expand_activation (Act  (None, None, None,   0          ['block7a_expand_bn[0][0]']      \n",
            " ivation)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_dwconv (DepthwiseConv2  (None, None, None,   10368      ['block7a_expand_activation[0][0]\n",
            " D)                             1152)                            ']                               \n",
            "                                                                                                  \n",
            " block7a_bn (BatchNormalization  (None, None, None,   4608       ['block7a_dwconv[0][0]']         \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_activation (Activation  (None, None, None,   0          ['block7a_bn[0][0]']             \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_se_excite (Multiply)   (None, None, None,   0           ['block7a_activation[0][0]',     \n",
            "                                1152)                             'block7a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_conv (Conv2D)  (None, None, None,   368640      ['block7a_se_excite[0][0]']      \n",
            "                                320)                                                              \n",
            "                                                                                                  \n",
            " block7a_project_bn (BatchNorma  (None, None, None,   1280       ['block7a_project_conv[0][0]']   \n",
            " lization)                      320)                                                              \n",
            "                                                                                                  \n",
            " top_conv (Conv2D)              (None, None, None,   409600      ['block7a_project_bn[0][0]']     \n",
            "                                1280)                                                             \n",
            "                                                                                                  \n",
            " top_bn (BatchNormalization)    (None, None, None,   5120        ['top_conv[0][0]']               \n",
            "                                1280)                                                             \n",
            "                                                                                                  \n",
            " top_activation (Activation)    (None, None, None,   0           ['top_bn[0][0]']                 \n",
            "                                1280)                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,571\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,571\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "F9K-_vvORl-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438463f4-f298-40db-ca2e-9db964a26326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n",
            "                                                                 \n",
            " global_average_pooling_laye  (None, 1280)             0         \n",
            " r (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,062,381\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 4,049,571\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Check summary of model constructed with Functional API\n",
        "model_0.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGYokAGrRsox"
      },
      "source": [
        "Our overall model has five layers but really, one of those layers (`efficientnetb0`) has 236 layers.\n",
        "\n",
        "You can see how the output shape started out as `(None, 224, 224, 3)` for the input layer (the shape of our images) but was transformed to be `(None, 10)` by the output layer (the shape of our labels), where `None` is the placeholder for the batch size.\n",
        "\n",
        "Notice too, the only trainable parameters in the model are those in the output layer.\n",
        "\n",
        "How do our model's training curves look?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bJxgUI6cRvu9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "0dfc84ab-18d3-45d8-8134-8a77a73f94f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Check out our model's training curves\n",
        "plot_loss_curves(history_10_percent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbABBbOZRyw3"
      },
      "source": [
        "## Getting a feature vector from a trained model\n",
        "\n",
        "> ðŸ¤” **Question:** What happens with the `tf.keras.layers.GlobalAveragePooling2D()` layer? I haven't seen it before.\n",
        "\n",
        "The [`tf.keras.layers.GlobalAveragePooling2D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D) layer transforms a 4D tensor into a 2D tensor by averaging the values across the inner-axes.\n",
        "\n",
        "The previous sentence is a bit of a mouthful, so let's see an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aU7rugjpkxf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594696a6-3f4e-4783-bcc9-f6671c559211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random input tensor:\n",
            " [[[[ 0.3274685  -0.8426258   0.3194337 ]\n",
            "   [-1.4075519  -2.3880599  -1.0392479 ]\n",
            "   [-0.5573232   0.539707    1.6994323 ]\n",
            "   [ 0.28893656 -1.5066116  -0.26454744]]\n",
            "\n",
            "  [[-0.59722406 -1.9171132  -0.62044144]\n",
            "   [ 0.8504023  -0.40604794 -3.0258412 ]\n",
            "   [ 0.9058464   0.29855987 -0.22561555]\n",
            "   [-0.7616443  -1.891714   -0.9384712 ]]\n",
            "\n",
            "  [[ 0.77852213 -0.47338897  0.97772694]\n",
            "   [ 0.24694404  0.20573747 -0.5256233 ]\n",
            "   [ 0.32410017  0.02545409 -0.10638497]\n",
            "   [-0.6369475   1.1603122   0.2507359 ]]\n",
            "\n",
            "  [[-0.41728497  0.40125778 -1.4145442 ]\n",
            "   [-0.59318566 -1.6617213   0.33567193]\n",
            "   [ 0.10815629  0.2347968  -0.56668764]\n",
            "   [-0.35819843  0.88698626  0.5274477 ]]]]\n",
            "\n",
            "2D global average pooled random tensor:\n",
            " [[-0.09368646 -0.45840445 -0.28855976]]\n",
            "\n",
            "Shape of input tensor: (1, 4, 4, 3)\n",
            "Shape of 2D global averaged pooled input tensor: (1, 3)\n"
          ]
        }
      ],
      "source": [
        "# Define input tensor shape (same number of dimensions as the output of efficientnetb0)\n",
        "input_shape = (1, 4, 4, 3)\n",
        "\n",
        "# Create a random tensor\n",
        "tf.random.set_seed(42)\n",
        "input_tensor = tf.random.normal(input_shape)\n",
        "print(f\"Random input tensor:\\n {input_tensor}\\n\")\n",
        "\n",
        "# Pass the random tensor through a global average pooling 2D layer\n",
        "global_average_pooled_tensor = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
        "print(f\"2D global average pooled random tensor:\\n {global_average_pooled_tensor}\\n\")\n",
        "\n",
        "# Check the shapes of the different tensors\n",
        "print(f\"Shape of input tensor: {input_tensor.shape}\")\n",
        "print(f\"Shape of 2D global averaged pooled input tensor: {global_average_pooled_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see the `tf.keras.layers.GlobalAveragePooling2D()` layer condensed the input tensor from shape `(1, 4, 4, 3)` to `(1, 3)`. It did so by averaging the `input_tensor` across the middle two axes.\n",
        "\n",
        "We can replicate this operation using the `tf.reduce_mean()` operation and specifying the appropriate axes."
      ],
      "metadata": {
        "id": "v-aYjDS9_h-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the same as GlobalAveragePooling2D()\n",
        "tf.reduce_mean(input_tensor, axis=[1, 2]) # average across the middle axes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H521fz5C_lhZ",
        "outputId": "16a9e566-6bd8-494b-e46b-173ebe7e1f1e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[-0.09368646, -0.45840445, -0.28855976]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing this not only makes the output of the base model compatible with the input shape requirement of our output layer (`tf.keras.layers.Dense()`), it also condenses the information found by the base model into a lower dimension **feature vector**.\n",
        "\n",
        "> ðŸ”‘ **Note:** One of the reasons feature extraction transfer learning is named how it is is because what often happens is a pretrained model outputs a **feature vector** (a long tensor of numbers, in our case, this is the output of the [`tf.keras.layers.GlobalAveragePooling2D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D) layer) which can then be used to extract patterns out of.\n",
        "\n",
        "> ðŸ›  **Practice:** Do the same as the above cell but for [`tf.keras.layers.GlobalMaxPool2D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool2D)."
      ],
      "metadata": {
        "id": "cya7RR8X_nwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running a series of transfer learning experiments\n",
        "\n",
        "We've seen the incredible results of transfer learning on 10% of the training data, what about 1% of the training data?\n",
        "\n",
        "What kind of results do you think we can get using 100x less data than the original CNN models we built ourselves?\n",
        "\n",
        "Why don't we answer that question while running the following modelling experiments:\n",
        "1. `model_1`: Use feature extraction transfer learning on 1% of the training data with data augmentation.\n",
        "2. `model_2`: Use feature extraction transfer learning on 10% of the training data with data augmentation.\n",
        "3. `model_3`: Use fine-tuning transfer learning on 10% of the training data with data augmentation.\n",
        "4. `model_4`: Use fine-tuning transfer learning on 100% of the training data with data augmentation.\n",
        "\n",
        "While all of the experiments will be run on different versions of the training data, they will all be evaluated on the same test dataset, this ensures the results of each experiment are as comparable as possible.\n",
        "\n",
        "All experiments will be done using the `EfficientNetB0` model within the `tf.keras.applications` module.\n",
        "\n",
        "To make sure we're keeping track of our experiments, we'll use our `create_tensorboard_callback()` function to log all of the model training logs.\n",
        "\n",
        "We'll construct each model using the Keras Functional API and instead of implementing data augmentation in the `ImageDataGenerator` class as we have previously, we're going to build it right into the model using the [`tf.keras.layers.experimental.preprocessing`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing) module.\n",
        "\n",
        "Let's begin by downloading the data for experiment 1, using feature extraction transfer learning on 1% of the training data with data augmentation."
      ],
      "metadata": {
        "id": "GmKyoCbb_pN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and unzip data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\n",
        "unzip_data(\"10_food_classes_1_percent.zip\")\n",
        "\n",
        "# Create training and test dirs\n",
        "train_dir_1_percent = \"10_food_classes_1_percent/train/\"\n",
        "test_dir = \"10_food_classes_1_percent/test/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1Z5Awzq_qun",
        "outputId": "b9d44b18-8b05-4c2e-e9b5-c23b0d41a44c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-05 16:07:27--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.201.128, 74.125.202.128, 74.125.69.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.201.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 133612354 (127M) [application/zip]\n",
            "Saving to: â€˜10_food_classes_1_percent.zipâ€™\n",
            "\n",
            "10_food_classes_1_p 100%[===================>] 127.42M   245MB/s    in 0.5s    \n",
            "\n",
            "2022-01-05 16:07:28 (245 MB/s) - â€˜10_food_classes_1_percent.zipâ€™ saved [133612354/133612354]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-WSVPAae_so3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "05_transfer_learning_in_tensorflow_part_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOiJ8TiCerXRyQ51fclMoMe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}